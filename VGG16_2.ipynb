{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data set split: 75-15-10\n",
    "\n",
    "import os\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import Sequential\n",
    "from tensorflow.python.keras.layers  import Convolution2D , ZeroPadding2D\n",
    "from tensorflow.python.keras.layers  import GlobalAveragePooling2D , MaxPooling2D , Activation \n",
    "from tensorflow.python.keras.layers  import Flatten , Dropout\n",
    "from tensorflow.python.keras.layers  import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding2d (ZeroPadding2 (None, 226, 226, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 226, 226, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPaddin (None, 114, 114, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPaddin (None, 114, 114, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPaddin (None, 58, 58, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPaddin (None, 58, 58, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPaddin (None, 58, 58, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPaddin (None, 30, 30, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_8 (ZeroPaddin (None, 30, 30, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_9 (ZeroPaddin (None, 30, 30, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_10 (ZeroPaddi (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_11 (ZeroPaddi (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_12 (ZeroPaddi (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 16388     \n",
      "=================================================================\n",
      "Total params: 134,276,932\n",
      "Trainable params: 134,276,932\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def define_model():\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1,1),input_shape=(224,224,3)))\n",
    "    model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256,(3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512,(3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512,(3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2) , padding='same'))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512,(3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model = define_model()\n",
    "    print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = tf.keras.optimizers.SGD(lr=1e-6, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy' , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5694 images belonging to 4 classes.\n",
      "Found 1140 images belonging to 4 classes.\n",
      "Found 760 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator()\n",
    "validation_datagen = ImageDataGenerator()\n",
    "test_datagen = ImageDataGenerator()\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('D3/train/', \n",
    "                                                 target_size = (224,224), \n",
    "                                                 batch_size = 10, \n",
    "                                                 class_mode = 'categorical', \n",
    "                                                 shuffle = True)\n",
    "\n",
    "validation_set = test_datagen.flow_from_directory('D3/validation/', \n",
    "                                            target_size = (224,224), \n",
    "                                            batch_size = 1, \n",
    "                                            class_mode = 'categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('D3/test/', \n",
    "                                            target_size = (224,224), \n",
    "                                            batch_size = 1, \n",
    "                                            class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 570 steps, validate for 1140 steps\n",
      "Epoch 1/30\n",
      "569/570 [============================>.] - ETA: 1s - loss: 1.4304 - accuracy: 0.2729\n",
      "Epoch 00001: saving model to training_1/cp.ckpt\n",
      "570/570 [==============================] - 755s 1s/step - loss: 1.4306 - accuracy: 0.2727 - val_loss: 1.3272 - val_accuracy: 0.3930\n",
      "Epoch 2/30\n",
      "569/570 [============================>.] - ETA: 1s - loss: 1.3689 - accuracy: 0.3091\n",
      "Epoch 00002: saving model to training_1/cp.ckpt\n",
      "570/570 [==============================] - 757s 1s/step - loss: 1.3690 - accuracy: 0.3087 - val_loss: 1.3088 - val_accuracy: 0.4535\n",
      "Epoch 3/30\n",
      "569/570 [============================>.] - ETA: 1s - loss: 1.3409 - accuracy: 0.3344\n",
      "Epoch 00003: saving model to training_1/cp.ckpt\n",
      "570/570 [==============================] - 757s 1s/step - loss: 1.3413 - accuracy: 0.3342 - val_loss: 1.2907 - val_accuracy: 0.4956\n",
      "Epoch 4/30\n",
      "569/570 [============================>.] - ETA: 1s - loss: 1.3265 - accuracy: 0.3527\n",
      "Epoch 00004: saving model to training_1/cp.ckpt\n",
      "570/570 [==============================] - 763s 1s/step - loss: 1.3265 - accuracy: 0.3523 - val_loss: 1.2710 - val_accuracy: 0.5333\n",
      "Epoch 5/30\n",
      "569/570 [============================>.] - ETA: 1s - loss: 1.3059 - accuracy: 0.3717\n",
      "Epoch 00005: saving model to training_1/cp.ckpt\n",
      "570/570 [==============================] - 759s 1s/step - loss: 1.3059 - accuracy: 0.3718 - val_loss: 1.2495 - val_accuracy: 0.5675\n",
      "Epoch 6/30\n",
      "569/570 [============================>.] - ETA: 1s - loss: 1.2848 - accuracy: 0.4055\n",
      "Epoch 00006: saving model to training_1/cp.ckpt\n",
      "570/570 [==============================] - 727s 1s/step - loss: 1.2848 - accuracy: 0.4057 - val_loss: 1.2251 - val_accuracy: 0.5833\n",
      "Epoch 7/30\n",
      "569/570 [============================>.] - ETA: 1s - loss: 1.2606 - accuracy: 0.4307\n",
      "Epoch 00007: saving model to training_1/cp.ckpt\n",
      "570/570 [==============================] - 829s 1s/step - loss: 1.2604 - accuracy: 0.4310 - val_loss: 1.1921 - val_accuracy: 0.6237\n",
      "Epoch 8/30\n",
      "569/570 [============================>.] - ETA: 1s - loss: 1.2271 - accuracy: 0.4761\n",
      "Epoch 00008: saving model to training_1/cp.ckpt\n",
      "570/570 [==============================] - 958s 2s/step - loss: 1.2272 - accuracy: 0.4759 - val_loss: 1.1544 - val_accuracy: 0.6272\n",
      "Epoch 9/30\n",
      "569/570 [============================>.] - ETA: 1s - loss: 1.1986 - accuracy: 0.4886\n",
      "Epoch 00009: saving model to training_1/cp.ckpt\n",
      "570/570 [==============================] - 1021s 2s/step - loss: 1.1990 - accuracy: 0.4884 - val_loss: 1.1073 - val_accuracy: 0.6482\n",
      "Epoch 10/30\n",
      "569/570 [============================>.] - ETA: 1s - loss: 1.1591 - accuracy: 0.5246\n",
      "Epoch 00010: saving model to training_1/cp.ckpt\n",
      "570/570 [==============================] - 1046s 2s/step - loss: 1.1592 - accuracy: 0.5242 - val_loss: 1.0449 - val_accuracy: 0.6947\n",
      "Epoch 11/30\n",
      "569/570 [============================>.] - ETA: 1s - loss: 1.0889 - accuracy: 0.5797\n",
      "Epoch 00011: saving model to training_1/cp.ckpt\n",
      "570/570 [==============================] - 758s 1s/step - loss: 1.0894 - accuracy: 0.5794 - val_loss: 0.9646 - val_accuracy: 0.7482\n",
      "Epoch 12/30\n",
      "569/570 [============================>.] - ETA: 1s - loss: 1.0341 - accuracy: 0.6019\n",
      "Epoch 00012: saving model to training_1/cp.ckpt\n",
      "570/570 [==============================] - 713s 1s/step - loss: 1.0341 - accuracy: 0.6017 - val_loss: 0.8805 - val_accuracy: 0.7360\n",
      "Epoch 13/30\n",
      "569/570 [============================>.] - ETA: 1s - loss: 0.9489 - accuracy: 0.6524\n",
      "Epoch 00013: saving model to training_1/cp.ckpt\n",
      "570/570 [==============================] - 720s 1s/step - loss: 0.9488 - accuracy: 0.6524 - val_loss: 0.7840 - val_accuracy: 0.7763\n",
      "Epoch 14/30\n",
      "569/570 [============================>.] - ETA: 1s - loss: 0.8651 - accuracy: 0.6798\n",
      "Epoch 00014: saving model to training_1/cp.ckpt\n",
      "570/570 [==============================] - 709s 1s/step - loss: 0.8650 - accuracy: 0.6800 - val_loss: 0.6950 - val_accuracy: 0.8158\n",
      "Epoch 15/30\n",
      "569/570 [============================>.] - ETA: 1s - loss: 0.8080 - accuracy: 0.7050\n",
      "Epoch 00015: saving model to training_1/cp.ckpt\n",
      "570/570 [==============================] - 709s 1s/step - loss: 0.8077 - accuracy: 0.7051 - val_loss: 0.6137 - val_accuracy: 0.8570\n",
      "Epoch 16/30\n",
      "569/570 [============================>.] - ETA: 1s - loss: 0.7338 - accuracy: 0.7363\n",
      "Epoch 00016: saving model to training_1/cp.ckpt\n",
      "570/570 [==============================] - 707s 1s/step - loss: 0.7336 - accuracy: 0.7366 - val_loss: 0.5432 - val_accuracy: 0.8684\n",
      "Epoch 17/30\n",
      "569/570 [============================>.] - ETA: 1s - loss: 0.6750 - accuracy: 0.7614\n",
      "Epoch 00017: saving model to training_1/cp.ckpt\n",
      "570/570 [==============================] - 704s 1s/step - loss: 0.6750 - accuracy: 0.7615 - val_loss: 0.4900 - val_accuracy: 0.8693\n",
      "Epoch 18/30\n",
      "569/570 [============================>.] - ETA: 1s - loss: 0.6214 - accuracy: 0.7796\n",
      "Epoch 00018: saving model to training_1/cp.ckpt\n",
      "570/570 [==============================] - 705s 1s/step - loss: 0.6215 - accuracy: 0.7796 - val_loss: 0.4705 - val_accuracy: 0.8658\n",
      "Epoch 19/30\n",
      "569/570 [============================>.] - ETA: 1s - loss: 0.5552 - accuracy: 0.8174\n",
      "Epoch 00019: saving model to training_1/cp.ckpt\n",
      "570/570 [==============================] - 703s 1s/step - loss: 0.5551 - accuracy: 0.8175 - val_loss: 0.3793 - val_accuracy: 0.9219\n",
      "Epoch 20/30\n",
      "569/570 [============================>.] - ETA: 1s - loss: 0.5039 - accuracy: 0.8302\n",
      "Epoch 00020: saving model to training_1/cp.ckpt\n",
      "570/570 [==============================] - 706s 1s/step - loss: 0.5035 - accuracy: 0.8305 - val_loss: 0.3445 - val_accuracy: 0.9211\n",
      "Epoch 21/30\n",
      "569/570 [============================>.] - ETA: 1s - loss: 0.4659 - accuracy: 0.8427\n",
      "Epoch 00021: saving model to training_1/cp.ckpt\n",
      "570/570 [==============================] - 708s 1s/step - loss: 0.4662 - accuracy: 0.8426 - val_loss: 0.3049 - val_accuracy: 0.9360\n",
      "Epoch 22/30\n",
      "569/570 [============================>.] - ETA: 1s - loss: 0.4226 - accuracy: 0.8656\n",
      "Epoch 00022: saving model to training_1/cp.ckpt\n",
      "570/570 [==============================] - 707s 1s/step - loss: 0.4222 - accuracy: 0.8658 - val_loss: 0.2753 - val_accuracy: 0.9412\n",
      "Epoch 23/30\n",
      "569/570 [============================>.] - ETA: 1s - loss: 0.4139 - accuracy: 0.8666\n",
      "Epoch 00023: saving model to training_1/cp.ckpt\n",
      "570/570 [==============================] - 698s 1s/step - loss: 0.4135 - accuracy: 0.8669 - val_loss: 0.3165 - val_accuracy: 0.9096\n",
      "Epoch 24/30\n",
      "569/570 [============================>.] - ETA: 1s - loss: 0.3791 - accuracy: 0.8767\n",
      "Epoch 00024: saving model to training_1/cp.ckpt\n",
      "570/570 [==============================] - 907s 2s/step - loss: 0.3787 - accuracy: 0.8769 - val_loss: 0.2360 - val_accuracy: 0.9482\n",
      "Epoch 25/30\n",
      "569/570 [============================>.] - ETA: 1s - loss: 0.3535 - accuracy: 0.8858\n",
      "Epoch 00025: saving model to training_1/cp.ckpt\n",
      "570/570 [==============================] - 931s 2s/step - loss: 0.3539 - accuracy: 0.8857 - val_loss: 0.2224 - val_accuracy: 0.9439\n",
      "Epoch 26/30\n",
      "569/570 [============================>.] - ETA: 1s - loss: 0.3311 - accuracy: 0.8927\n",
      "Epoch 00026: saving model to training_1/cp.ckpt\n",
      "570/570 [==============================] - 951s 2s/step - loss: 0.3312 - accuracy: 0.8927 - val_loss: 0.2135 - val_accuracy: 0.9430\n",
      "Epoch 27/30\n",
      "569/570 [============================>.] - ETA: 0s - loss: 0.3158 - accuracy: 0.9010\n",
      "Epoch 00027: saving model to training_1/cp.ckpt\n",
      "570/570 [==============================] - 690s 1s/step - loss: 0.3157 - accuracy: 0.9009 - val_loss: 0.1921 - val_accuracy: 0.9509\n",
      "Epoch 28/30\n",
      "569/570 [============================>.] - ETA: 1s - loss: 0.2927 - accuracy: 0.9073\n",
      "Epoch 00028: saving model to training_1/cp.ckpt\n",
      "570/570 [==============================] - 700s 1s/step - loss: 0.2926 - accuracy: 0.9074 - val_loss: 0.1904 - val_accuracy: 0.9500\n",
      "Epoch 29/30\n",
      "569/570 [============================>.] - ETA: 0s - loss: 0.2777 - accuracy: 0.9159\n",
      "Epoch 00029: saving model to training_1/cp.ckpt\n",
      "570/570 [==============================] - 695s 1s/step - loss: 0.2775 - accuracy: 0.9161 - val_loss: 0.1739 - val_accuracy: 0.9535\n",
      "Epoch 30/30\n",
      "569/570 [============================>.] - ETA: 0s - loss: 0.2724 - accuracy: 0.9163\n",
      "Epoch 00030: saving model to training_1/cp.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "570/570 [==============================] - 693s 1s/step - loss: 0.2723 - accuracy: 0.9161 - val_loss: 0.1651 - val_accuracy: 0.9579\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2a7c425990>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_set, epochs = 30, validation_data = validation_set, verbose = 1, callbacks = [cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/himanshu/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: saved_model/GoogLeNet-1/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('saved_model/GoogLeNet-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760/760 [==============================] - 90s 119ms/step - loss: 0.1844 - accuracy: 0.9526\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/GoogLeNet-1b/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('saved_model/GoogLeNet-1b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a .pb version of model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tf.keras.models.save_model(model, filepath='saved_model/', include_optimizer=True)\n",
    "# Same function as above command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model('saved_model/GoogLeNet-1b')\n",
    "tflite_model = converter.convert()\n",
    "open(\"converted_model.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
